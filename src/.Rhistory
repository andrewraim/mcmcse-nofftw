setwd("~/Desktop/GitHub/GitHub/mcmcse/src")
library(Rcpp)
sourceCpp('batchsize.cpp')
install.packages('testthat', type = 'source')
batchSize <- function(x, method = c("bm", "obm", "bartlett", "tukey", "sub"), g = NULL, fast = TRUE)
{
method <- match.arg(method)
chain <- as.matrix(x)
if(!is.matrix(chain) && !is.data.frame(chain))
stop("'x' must be a matrix or data frame.")
p <- ncol(chain)
n <- sum(!is.na(chain[,1])) # number of non-missing rows
if (is.function(g))
{
chain <- apply(chain, 1, g)
if(is.vector(chain))
{
chain <- as.matrix(chain)
}else
{
chain <- t(chain)
}
}
if(n < (p+1))
stop("sample size is insufficient for a Markov chain of this dimension")
order.max <- min(p, n - 1L, floor(10 * log10(n))) # Maximum order up to which AR is fit
xacf = matrix(, nrow = order.max+1, ncol = p)
if(fast)  {                                       # Use only the tail of the chain to calculate acf
last = min(n, 5e4)  # lenght of tail used
chain2 = as.matrix(chain[(n-last+1):n,])
xacf = sapply(1:p, function(i) acf(chain2[,i], type = "covariance", lag.max = order.max, plot = FALSE,
demean=TRUE, na.action = na.pass)$acf)
}
else  {                                           # use the entire chain for acf calculation
xacf = sapply(1:p, function(i) acf(chain[,i], type = "covariance", lag.max = order.max, plot = FALSE,
demean=TRUE, na.action = na.pass)$acf)
}
threshold = qnorm((1.95)/2)/sqrt(n)              # threshold used in confidence interaval calculation
b = batchsize_cpp(n, p, xacf, order.max, method, threshold)
b <- min(b, floor(n / (p + 1)))
if(n > 10)
b <- min(b, floor(n/10))
b <- floor(b)
return(b)
}
eureka <- function(order_max, r, g, coefs, var, a, threshold) {
v = r[1]
d = r[2]
a[1] = 1.0
coefs[1,1] = g[2]/v
ans = list("vars" = var, "coefs" = coefs, "order" = order_max)
if(abs(coefs[1,1]) <= threshold) {
ans$vars = var
ans$coefs = coefs
ans$order = 0
return(ans)
}
q = coefs[1,1] * r[2]
var[1] = (1 - coefs[1,1]*coefs[1,1]) * r[1]
if(order_max == 1) {
ans$vars = var
ans$coefs = coefs
ans$order = 1
return(ans)
}
for(l in 2:order_max) {
a[l] = -d/v
if(l > 2) {
l1 = (l-2)/2
l2 = l1+1
for(j in 2:l2) {
hold = a[j]
k = l-j+1
a[j] = a[j] + a[l] * a[k]
a[k] = a[k] + a[l] * hold
}
if((2*l1) != (l-2))
a[l2+1] = a[l2+1] * (1.0 + a[l])
}
v = v + a[l] * d
coefs[l,l] = (g[l+1] - q)/v
if(abs(coefs[l,l]) <= threshold) {
ans$vars = var
ans$coefs = coefs
ans$order = l-1
return(ans)
}
for(j in 1:(l-1)) {
coefs[l,j] = coefs[l-1,j] + coefs[l,l] * a[l-j+1]
}
var[l] = var[l-1] * (1 - coefs[l,l]*coefs[l,l])
if(l == order_max) {
ans$vars = var
ans$vars = coefs
ans$order = order_max
return(ans)
}
d = 0.0
q = 0.0
for(i in 1:l) {
k = l-i+2
d = d + a[i] * r[k]
q = q + coefs[l,i] * r[k]
}
}
ans$vars = var
ans$coefs = coefs
ans$order = order_max
return(ans)
}
ar_yw <- function(order.max, r, g, coefs, var, a, threshold, n) {
ans = eureka(order.max, r, g, coefs, var, a, threshold)
coef_vec = numeric(ans$order)
if(ans$order> 0)  {
coef_vec = t(ans$coefs[ans$order, 1:ans$order])
var_pred = ans$vars[ans$order]
}
else{
var_pred = r[1]
}
var_pred = var_pred*n/(n-(ans$order+1))
ret = list("coefs" = coef_vec, "vars" = var_pred, "order" = ans$order)
return(ret)
}
arp_approx <- function(xacf, order.max, n)
{
threshold = qnorm((1.95)/2)/sqrt(n)
# Fitting a univariate AR(m) model
ar.fit <- ar_yw(order.max, xacf, xacf, matrix(0, nrow = order.max, ncol = order.max),
numeric(order.max), numeric(order.max), threshold, n)
# estimated autocovariances
gammas <- xacf #as.numeric(acf(x, type = "covariance", lag.max = ar.fit$order, plot = FALSE)$acf)
spec <- ar.fit$vars/(1-sum(ar.fit$coefs))^2  #asym variance
if(ar.fit$order != 0)
{
foo <- 0
for(i in 1:ar.fit$order)
{
for(k in 1:i)
{
foo <- foo + ar.fit$coefs[i]*k*gammas[abs(k-i)+1]
}
}
Gamma <- 2*(foo + (spec - gammas[1])/2 *sum(1:ar.fit$order * ar.fit$coefs)  )/(1-sum(ar.fit$coefs))
} else{
Gamma <- 0
}
rtn <- cbind(Gamma, spec)
colnames(rtn) <- c("Gamma", "Sigma")
return(rtn)
}
test_batchSize <- function(x, method = c("bm", "obm", "bartlett", "tukey"), g = NULL)  {
method = match.arg(method)
chain <- as.matrix(x)
if(!is.matrix(chain) && !is.data.frame(chain))
stop("'x' must be a matrix or data frame.")
if (is.function(g))
{
chain <- apply(chain, 1, g)
if(is.vector(chain))
{
chain <- as.matrix(chain)
}else
{
chain <- t(chain)
}
}
n <- dim(chain)[1]
p <- dim(chain)[2]
if(n < (p+1))
stop("sample size is insufficient for a Markov chain of this dimension")
order.max <- min(p, n - 1L, floor(10 * log10(n))) # Maximum order up to which AR is fit
xacf = matrix(, nrow = order.max+1, ncol = p)
xacf = sapply(1:p, function(i) acf(chain[,i], type = "covariance", lag.max = order.max, plot =
FALSE, demean=TRUE, na.action = na.pass)$acf)
ar_fit <- apply(xacf, 2, arp_approx, order.max = order.max, n = n)^2
coeff <- ( sum(ar_fit[1,])/sum(ar_fit[2,]) )^(1/3)
method = match.arg(method)
b.const <- (3/2*n)*(method == "obm" || method == "bartlett" || method == "tukey") + (n)*(method == "bm")
b <- b.const^(1/3) * coeff
if(b <= 1) b <- 1
b <- floor(b)
b <- min(b, floor(n / (p + 1)))
if(n > 10)
b = min(b, floor(n/10))
b <- floor(b)
return(b)
}
Gibbs_sampler <- function(mu1, mu2, a, b, rho, init, n) {
X <- matrix(0, nrow = n, ncol = 2)
X[1, 1] = init[1]
X[1, 2] = init[2]
for (i in 2:n) {
X[i, 1] = rnorm(1, mu1 + (rho / b) * (X[i - 1, 2] - mu2), sqrt(a - (rho ^ 2) / b))
X[i, 2] = rnorm(1, mu2 + (rho / a) * (X[i, 1] - mu1), sqrt(b - (rho ^ 2) / a))
}
return(X)
}
sourceCpp('lag.cpp')
set.seed(93972)
mvg = Gibbs_sampler(2, 50, 1, 1, 0.5, c(2, 50), 1e4)
test_batchSize(mvg)
batchSize(mvg, fast = FALSE)
set.seed(93972)
set.seed(10)
mvg = Gibbs_sampler(2, 50, 1, 1, 0.5, c(2, 50), 1e4)
test_batchSize(mvg)
batchSize(mvg, fast = FALSE)
set.seed(93972)
mvg = Gibbs_sampler(2, 50, 1, 1, 0.5, c(2, 50), 1e4)
test_batchSize(mvg)
batchSize(mvg, fast = FALSE)
